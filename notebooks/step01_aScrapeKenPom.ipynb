{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape KenPom\n",
    "# https://kenpom.com/index.php?y=2008\n",
    "# https://www.kaggle.com/code/walterhan/scrape-kenpom-data\n",
    "# https://www.geeksforgeeks.org/scrape-tables-from-any-website-using-python/\n",
    "# https://medium.com/analytics-vidhya/how-to-scrape-a-table-from-website-using-python-ce90d0cfb607\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab KenPom 2008 to 2022\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "season = np.arange(2008,2023,1)\n",
    "allkp = pd.DataFrame(columns = ['Year','Team','Conf','AdjEM','AdjO','AdjD','AdjT','SOSEM','SOSO','SOSD'])\n",
    "for y in season:\n",
    "    req = Request(\n",
    "        url=f'https://kenpom.com/index.php?y={y}', \n",
    "        headers={'User-Agent': 'Mozilla/5.0'}\n",
    "    )\n",
    "    webpage = urlopen(req).read()\n",
    "    soup =BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', class_=None)\n",
    "    \n",
    "    for row in table.tbody.find_all('tr'):    \n",
    "        # Find all data for each column\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        if(columns != []):\n",
    "            \n",
    "            Team = columns[1].text.strip()\n",
    "            Conf = columns[2].text.strip()\n",
    "            \n",
    "            AdjEM = columns[4].text.strip()\n",
    "            AdjO = columns[5].text.strip()\n",
    "            AdjD = columns[7].text.strip()\n",
    "            AdjT = columns[9].text.strip()\n",
    "            SOSEM = columns[13].text.strip()\n",
    "            SOSO = columns[15].text.strip()\n",
    "            SOSD = columns[17].text.strip()\n",
    "            newrow = [y,Team,Conf,AdjEM,AdjO,AdjD,AdjT,SOSEM,SOSO,SOSD]\n",
    "            allkp.loc[len(allkp)]=newrow\n",
    "            #newrow = pd.DataFrame({'Year':2008,'Team': Team,'Conf':Conf,'AdjEM':AdjEM,'AdjO':AdjO,'AdjD':AdjD,'AdjT':AdjT,'SOSEM':SOSEM,'SOSO':SOSO,'SOSD':SOSD})\n",
    "            #allkp = pd.concat(allkp,newrow)\n",
    "            allkp['Team'] = allkp['Team'].str.replace('\\d+','',regex=True).str.replace('*','',regex=True).str.rstrip()\n",
    "allkp.to_csv('step01_kenpom0823.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab KenPom 2023\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "allkp = pd.read_csv('step01_kenpom0823.csv')\n",
    "allkp = allkp[allkp['Year']!=2023]\n",
    "y = 2023\n",
    "\n",
    "req = Request(\n",
    "    url=f'https://kenpom.com/index.php?y={y}', \n",
    "    headers={'User-Agent': 'Mozilla/5.0'}\n",
    ")\n",
    "webpage = urlopen(req).read()\n",
    "soup =BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "table = soup.find('table', class_=None)\n",
    "\n",
    "for row in table.tbody.find_all('tr'):    \n",
    "    # Find all data for each column\n",
    "    columns = row.find_all('td')\n",
    "    \n",
    "    if(columns != []):\n",
    "        \n",
    "        Team = columns[1].text.strip()\n",
    "        Conf = columns[2].text.strip()\n",
    "        \n",
    "        AdjEM = columns[4].text.strip()\n",
    "        AdjO = columns[5].text.strip()\n",
    "        AdjD = columns[7].text.strip()\n",
    "        AdjT = columns[9].text.strip()\n",
    "        SOSEM = columns[13].text.strip()\n",
    "        SOSO = columns[15].text.strip()\n",
    "        SOSD = columns[17].text.strip()\n",
    "        newrow = [y,Team,Conf,AdjEM,AdjO,AdjD,AdjT,SOSEM,SOSO,SOSD]\n",
    "        allkp.loc[len(allkp)]=newrow\n",
    "        #newrow = pd.DataFrame({'Year':2008,'Team': Team,'Conf':Conf,'AdjEM':AdjEM,'AdjO':AdjO,'AdjD':AdjD,'AdjT':AdjT,'SOSEM':SOSEM,'SOSO':SOSO,'SOSD':SOSD})\n",
    "        #allkp = pd.concat(allkp,newrow)\n",
    "        allkp['Team'] = allkp['Team'].str.replace('\\d+','',regex=True).str.replace('*','',regex=True).str.rstrip()\n",
    "\n",
    "\n",
    "allkp.to_csv('step01_kenpom0823.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = allkp['Team'].unique()\n",
    "b = pd.DataFrame({'tm':sorted(a)})\n",
    "b.to_csv('aaa.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75a0be042a4beffa7bfe652d9ca9055e675071b6b5ebd40357e1d67e4cb4d822"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
